from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import learning_curve
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.model_selection import train_test_split
from fuzzywuzzy import fuzz
import xgboost as xgb
import warnings

warnings.filterwarnings("ignore")

# Step 1: Load the Datasets
gpu_specs = pd.read_csv('gpu_specs_v6.csv')
benchmarks = pd.read_csv('GPU_scores_graphicsAPIs.csv')

# ---- DATASET 1: GPU SPECS ----
print("\n--- GPU Specs Dataset Overview ---")
print("Shape of GPU Specs Dataset:", gpu_specs.shape)
print("Columns in GPU Specs Dataset:", gpu_specs.columns.tolist())
print("First 5 rows of GPU Specs Dataset:\n", gpu_specs.head())
print("\nMissing Values in GPU Specs Dataset:\n", gpu_specs.isnull().sum())

# Step 2A: Clean GPU Specs Dataset
gpu_specs['manufacturer'] = gpu_specs['manufacturer'].str.strip().str.lower()
gpu_specs = gpu_specs[gpu_specs['manufacturer']
                      == 'nvidia']  # Filter for NVIDIA GPUs
gpu_specs.drop(columns=['manufacturer'], inplace=True)

# Handle missing values
numerical_columns = ['memSize', 'memBusWidth', 'gpuClock', 'memClock']
gpu_specs[numerical_columns] = gpu_specs[numerical_columns].fillna(
    gpu_specs[numerical_columns].median()
)
gpu_specs['memType'] = gpu_specs['memType'].fillna(
    gpu_specs['memType'].mode()[0])

# Print values used to fill missing data
print("\n--- Missing Value Handling in GPU Specs ---")
for col in numerical_columns:
    print(
        f"Filled missing values in {col} with median value: {gpu_specs[col].median()}")
print(
    f"Filled missing values in 'memType' with mode: {gpu_specs['memType'].mode()[0]}")


# Map memory types to simplified categories
mem_type_mapping = {
    'GDDR5': 'GDDR5', 'GDDR5X': 'GDDR5',
    'GDDR6': 'GDDR6', 'GDDR6X': 'GDDR6',
    'HBM2': 'HBM2', 'HBM': 'HBM'
}
gpu_specs['memType'] = gpu_specs['memType'].map(
    mem_type_mapping).fillna('Other')

# Encode memory type for analysis
label_encoder_specs = LabelEncoder()
gpu_specs['memType_encoded'] = label_encoder_specs.fit_transform(
    gpu_specs['memType'])

# Feature engineering: Calculate memory bandwidth
gpu_specs['memoryBandwidth_GBs'] = (
    gpu_specs['memBusWidth'] * gpu_specs['memClock'] * 2 / 8
)

# ---- DATASET 2: BENCHMARKS ----
print("\n--- Benchmarks Dataset Overview ---")
print("Shape of Benchmarks Dataset:", benchmarks.shape)
print("Columns in Benchmarks Dataset:", benchmarks.columns.tolist())
print("First 5 rows of Benchmarks Dataset:\n", benchmarks.head())
print("\nMissing Values in Benchmarks Dataset:\n", benchmarks.isnull().sum())

# Step 2B: Clean Benchmarks Dataset
benchmarks['Manufacturer'] = benchmarks['Manufacturer'].str.strip().str.lower()
benchmarks = benchmarks[benchmarks['Manufacturer']
                        == 'nvidia']  # Filter for NVIDIA GPUs

# Fill missing CUDA and OpenCL values in benchmarks dataset
benchmarks['CUDA'] = benchmarks['CUDA'].fillna(benchmarks['CUDA'].median())
benchmarks['OpenCL'] = benchmarks['OpenCL'].fillna(
    benchmarks['OpenCL'].median())

# Print values used to fill missing data
print("\n--- Missing Value Handling in Benchmarks ---")
print(
    f"Filled missing values in 'CUDA' with median value: {benchmarks['CUDA'].median()}")
print(
    f"Filled missing values in 'OpenCL' with median value: {benchmarks['OpenCL'].median()}")

# ---- STEP 3: MATCH AND COMBINE DATASETS ----
# Fuzzy matching function
def fuzzy_match(row, choices, threshold=80):
    best_match = None
    best_score = 0
    for choice in choices:
        score = fuzz.token_sort_ratio(row, choice)
        if score > best_score and score >= threshold:
            best_score = score
            best_match = choice
    return best_match


# Extract unique device names
gpu_specs_products = gpu_specs['productName'].unique()
benchmarks_devices = benchmarks['Device'].unique()

# Perform fuzzy matching for product names
gpu_specs['matched_device'] = gpu_specs['productName'].apply(
    lambda x: fuzzy_match(x, benchmarks_devices)
)

# Select only relevant columns before merging
gpu_specs_relevant_columns = ['productName', 'memSize', 'memBusWidth',
                              'gpuClock', 'memClock', 'memType', 'memoryBandwidth_GBs', 'matched_device']
benchmarks_relevant_columns = ['Device', 'CUDA', 'OpenCL']

# Merge datasets on matched device names
combined_data = pd.merge(
    gpu_specs[gpu_specs_relevant_columns], benchmarks[benchmarks_relevant_columns],
    left_on='matched_device', right_on='Device', how='inner'
)

# Drop the 'matched_device' and 'Device' columns, if needed
combined_data.drop(columns=['matched_device', 'Device'], inplace=True)

# ---- OVERVIEW OF COMBINED DATASET ----
print("\n--- Combined Dataset Overview ---")
print("Shape of Combined Dataset:", combined_data.shape)
print("Columns in Combined Dataset:", combined_data.columns.tolist())
print("First 5 rows of Combined Dataset:\n", combined_data.head())
print("\nMissing Values in Combined Dataset:\n", combined_data.isnull().sum())


# Ensure memType exists in the final merged dataset
print("Columns in the merged dataset:", combined_data.columns)

# Save the final combined dataset to a CSV
combined_data.to_csv('combined_gpu_data_with_benchmarks2.csv', index=False)

# ---- STEP 4: EXPLORATORY DATA ANALYSIS ----
sns.set_theme(style="whitegrid")

# Enhanced: Distribution of Memory Size
plt.figure(figsize=(14, 8))  # Slightly larger for better readability

# Histogram with KDE
sns.histplot(
    combined_data['memSize'],
    bins=20,  # Smaller bin width for more granularity
    kde=True,
    color='skyblue',
    edgecolor='black',
    linewidth=1.2
)

# Title and Axes Labels
plt.title('Frequency Distribution of GPU Memory Sizes (in GB)',
          fontsize=20, pad=15)
plt.xlabel('Memory Size (GB)', fontsize=16, labelpad=10)
plt.ylabel('Count', fontsize=16, labelpad=10)

# X-Axis and Y-Axis Ticks
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)

# Annotations for Key Insights
plt.axvline(x=10, color='red', linestyle='--', linewidth=1.5,
            label='Common Memory Limit (10 GB)')
plt.text(11, plt.ylim()[1]*0.8, 'Most devices <10 GB',
         color='red', fontsize=12)

# Highlighting outliers
plt.axvline(x=50, color='green', linestyle='--', linewidth=1.5,
            label='High-Capacity Devices (50+ GB)')
plt.text(51, plt.ylim()[1]*0.5, 'Outliers (50+ GB)',
         color='green', fontsize=12)

# Adding a Legend
plt.legend(fontsize=12, title='Annotations',
           title_fontsize=14, loc='upper right')

# Adding Grid for readability
plt.grid(visible=True, linestyle='--', linewidth=0.5, alpha=0.7)

# Tight Layout for cleaner spacing
plt.tight_layout()

# Display the plot
plt.show()


# Create a count plot by grouping by memType and memBusWidth
plt.figure(figsize=(12, 7))
sns.barplot(x='memBusWidth', hue='memType', data=gpu_specs, palette='viridis')
plt.title('Memory Bus Width Frequency by Memory Type',
          fontsize=18, fontweight='bold')
plt.xlabel('Memory Bus Width (bits)', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.xticks(fontsize=12, rotation=45)
plt.yticks(fontsize=12)
plt.tight_layout()
plt.show()

# Memory Type Distribution
plt.figure(figsize=(12, 7))
sns.countplot(data=gpu_specs, x='memType',
              palette='viridis', edgecolor='black')
plt.title('Distribution of Memory Types', fontsize=18, fontweight='bold')
plt.xlabel('Memory Type', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.xticks(fontsize=12, rotation=45)
plt.yticks(fontsize=12)
plt.tight_layout()
plt.show()

